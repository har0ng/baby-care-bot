import os
from dotenv import load_dotenv

load_dotenv()

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USER")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
import nest_asyncio
import streamlit as st
import uuid

from langchain_community.vectorstores.neo4j_vector import Neo4jVector
from langchain_community.chat_models import ChatOllama
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnablePassthrough
from langchain.prompts import PromptTemplate
from langchain.vectorstores.utils import filter_complex_metadata
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# import settings as sets  # NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD í¬í•¨

# ì¤‘ì²© ì´ë²¤íŠ¸ ë£¨í”„ ë°©ì§€
nest_asyncio.apply()

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class ChatPDF:
    def __init__(self):
        self.vector_store = None
        self.retriever = None
        self.chain = None
        self.chat_history = []
        self.current_user_id = None

        # LLM ëª¨ë¸ ë° í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        self.model = ChatOllama(model="gemma3:4b")
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)

        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ì—­í• : ì¸¤ë°ë ˆ ì–´ì‹œìŠ¤í„´íŠ¸, í•œêµ­ì–´+ì¼ë³¸ì–´ ë‹µë³€)
        self.prompt = PromptTemplate.from_template(
            """
            <s> [INST] ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ì¸¤ë°ë ˆ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
            ì•„ë˜ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ì•¼:

            {history}

            ì´ë²ˆ ì§ˆë¬¸: {question}
            ì°¸ê³  ìë£Œ (ì»¨í…ìŠ¤íŠ¸): {context}
            ì¼ë³¸ì–´ì™€ í•œêµ­ì–´ë¡œ 3ë¬¸ì¥ ì´ë‚´ë¡œ ê·€ì—½ê²Œ ëŒ€ë‹µí•´ì¤˜! [/INST]
            """
        )

    def set_user(self, user_id: str):
        self.current_user_id = user_id
        # Neo4jì— User ë…¸ë“œê°€ ì—†ìœ¼ë©´ ìƒì„±
        with self.vector_store._driver.session() as session:
            session.run("MERGE (:User {id: $uid})", uid=user_id)

    def ingest(self, pdf_file_path: str):
        st.write(f"ğŸ“„ PDF íŒŒì¼ ë¡œë“œ ì‹œì‘: {pdf_file_path}")
        docs = PyPDFLoader(file_path=pdf_file_path).load()
        st.write(f"âœ… PDF ë¡œë“œ ì™„ë£Œ, ë¬¸ì„œ ìˆ˜: {len(docs)}")

        st.write("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì‹œì‘")
        chunks = self.text_splitter.split_documents(docs)
        st.write(f"âœ… í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ, ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("ğŸ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì‹œì‘")
        chunks = filter_complex_metadata(chunks)
        st.write(f"âœ… ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ, í•„í„°ë§ í›„ ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("âš™ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”...")
        embeddings_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", task_type="RETRIEVAL_DOCUMENT")
        st.write("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

        st.write("ğŸ”¢ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")
        embed_info = []
        for i, chunk in enumerate(chunks):
            embedding_vector = embeddings_model.embed_query(chunk.page_content)
            embed_info.append({
                'text': chunk.page_content,
                'embedding': embedding_vector,
                'reference_text': chunk.metadata.get('source', f'chunk_{i}')
            })
        st.write(f"âœ… {len(embed_info)}ê°œì˜ ì²­í¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ")

        st.write("ğŸ“Š Neo4jì— ì„ë² ë”© ì—…ë¡œë“œ ì¤€ë¹„ ì¤‘...")
        text_embeddings = [(e['text'], e['embedding']) for e in embed_info]
        metadatas = [{'reference_text': e['reference_text']} for e in embed_info]

        self.vector_store = Neo4jVector.from_embeddings(
            text_embeddings=text_embeddings,
            embedding=embeddings_model,
            metadatas=metadatas,
            url=NEO4J_URI,
            username=NEO4J_USER,
            password=NEO4J_PASSWORD,
            database="neo4j",
            index_name="langchain_index",
            node_label="Document",
            embedding_node_property="embedding"
        )
        st.write("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

        self.retriever = self.vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={"k": 3, "score_threshold": 0.5}
        )
        st.write("âœ… ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ì™„ë£Œ")

        self.chain = (
            {"context": self.retriever, "question": RunnablePassthrough()}
            | self.prompt
            | self.model
            | StrOutputParser()
        )
        st.write("âœ… ì±— ì²´ì¸ ìƒì„± ì™„ë£Œ")

        # ì‚¬ìš©ì ë…¸ë“œ ìƒì„± (ì´ˆê¸°í™” í›„)
        if self.current_user_id:
            self.set_user(self.current_user_id)

    def get_past_user_interactions(self, user_id: str, limit: int = 3):
        with self.vector_store._driver.session() as session:
            result = session.run(
                """
                MATCH (u:User {id: $uid})-[:ASKED]->(q:Question)-[:RECEIVED_ANSWER]->(a:Answer)
                RETURN q.text AS question, a.text AS answer
                ORDER BY q.timestamp DESC
                LIMIT $limit
                """,
                uid=user_id,
                limit=limit
            )
            interactions = result.data()
            return interactions[::-1]  # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë ¬

    def _enrich_query(self, query: str, history: list):
        if not history:
            return query
        history_text = "\n".join([f"Q{i+1}: {h['question']}\nA{i+1}: {h['answer']}" for i, h in enumerate(history)])
        return f"{history_text}\n\ní˜„ì¬ ì§ˆë¬¸: {query}"

    def ask(self, query: str):
        if not self.chain:
            return "ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        # if not self.current_user_id:
        #     return "ì‚¬ìš©ì IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        # ì§ˆë¬¸ ì €ì¥
        question_id = str(uuid.uuid4())
        with self.vector_store._driver.session() as session:
            session.run(
            """
            MERGE (q:Question {id: $qid})
            SET q.text = $qtext, q.timestamp = datetime()
            """,
            qid=question_id, qtext=query
        )

        # ê³¼ê±° ëŒ€í™” ë¶ˆëŸ¬ì˜¤ê¸° ë° ì¿¼ë¦¬ ê°•í™”
        past_history = []
        enriched_query = self._enrich_query(query, past_history)

        # ì²´ì¸ ì‹¤í–‰
        response = self.chain.invoke({"question": enriched_query, "history": ""})

        # ë‹µë³€ ì €ì¥
        answer_id = str(uuid.uuid4())
        with self.vector_store._driver.session() as session:
            session.run(
                """
                MERGE (a:Answer {id: $aid})
                SET a.text = $atext, a.timestamp = datetime()
                MERGE (q:Question {id: $qid})
                MERGE (q)-[:RECEIVED_ANSWER]->(a)
                """,
                aid=answer_id, atext=response, qid=question_id
            )

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (optional)
        self.chat_history.append((query, response))

        return response

    def clear(self):
        self.vector_store = None
        self.retriever = None
        self.chain = None
        self.chat_history = []
        st.write("ì´ˆê¸°í™” ì™„ë£Œ!")

