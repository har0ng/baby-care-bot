import os
from dotenv import load_dotenv
import nest_asyncio
import streamlit as st
import uuid

from langchain_community.vectorstores.neo4j_vector import Neo4jVector
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.utilities import GoogleSearchAPIWrapper
from langchain.tools import Tool
from langchain.agents import tool

nest_asyncio.apply()
load_dotenv()

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USER")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GOOGLE_CSE_ID = os.getenv("GOOGLE_CSE_ID")

class ChatPDF:
    def __init__(self):
        self.vector_store = None
        self.retriever = None
        self.chain = None
        self.chat_history = []
        self.current_user_id = None

        # ëª¨ë¸ëª… "chat-bison-001" ì‚¬ìš©
        self.model = ChatGoogleGenerativeAI(model="models/chat-bison-001", temperature=0.3)
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)

    def set_user(self, user_id: str):
        self.current_user_id = user_id
        if self.vector_store:
            with self.vector_store._driver.session() as session:
                session.run("MERGE (:User {id: $uid})", uid=user_id)
        else:
            st.warning("ê²½ê³ : PDFê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ì‚¬ìš©ì ë…¸ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ingestë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

    def ingest(self, pdf_file_path: str):
        st.write(f"ğŸ“„ PDF ë¡œë“œ ì‹œì‘: {pdf_file_path}")
        docs = PyPDFLoader(file_path=pdf_file_path).load()
        st.write(f"âœ… PDF ë¡œë“œ ì™„ë£Œ, ë¬¸ì„œ ìˆ˜: {len(docs)}")

        st.write("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘")
        chunks = self.text_splitter.split_documents(docs)
        st.write(f"âœ… í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ, ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("ğŸ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¤‘")
        chunks = filter_complex_metadata(chunks)
        st.write(f"âœ… ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ, ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("âš™ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”")
        embeddings_model = GoogleGenerativeAIEmbeddings(model="embedding-001", task_type="RETRIEVAL_DOCUMENT")
        st.write("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

        st.write("ğŸ”¢ ì„ë² ë”© ìƒì„± ì¤‘")
        embed_info = []
        for i, chunk in enumerate(chunks):
            embedding_vector = embeddings_model.embed_query(chunk.page_content)
            embed_info.append({
                'text': chunk.page_content,
                'embedding': embedding_vector,
                'reference_text': chunk.metadata.get('source', f'chunk_{i}')
            })
        st.write(f"âœ… {len(embed_info)}ê°œì˜ ì„ë² ë”© ìƒì„± ì™„ë£Œ")

        st.write("ğŸ“Š Neo4j ë²¡í„° ìŠ¤í† ì–´ì— ì—…ë¡œë“œ ì¤‘")
        text_embeddings = [(e['text'], e['embedding']) for e in embed_info]
        metadatas = [{'reference_text': e['reference_text']} for e in embed_info]

        self.vector_store = Neo4jVector.from_embeddings(
            text_embeddings=text_embeddings,
            embedding=embeddings_model,
            metadatas=metadatas,
            url=NEO4J_URI,
            username=NEO4J_USER,
            password=NEO4J_PASSWORD,
            database="neo4j",
            index_name="langchain_index",
            node_label="Document",
            embedding_node_property="embedding"
        )
        st.write("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

        self.retriever = self.vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={"k": 3, "score_threshold": 0.5}
        )
        st.write("âœ… ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ì™„ë£Œ")

        self.setup_agent()
        st.write("âœ… ì—ì´ì „íŠ¸ ì„¤ì • ì™„ë£Œ")

        if self.current_user_id:
            self.set_user(self.current_user_id)

    def setup_agent(self):
        if not GOOGLE_API_KEY or not GOOGLE_CSE_ID:
            st.error("ì˜¤ë¥˜: Google API í‚¤ ë˜ëŠ” CSE IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        search = GoogleSearchAPIWrapper(google_api_key=GOOGLE_API_KEY, google_cse_id=GOOGLE_CSE_ID)

        google_search_tool = Tool(
            name="google_search",
            description="ìµœì‹  ì •ë³´ë‚˜ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            func=search.run,
        )

        # ì—¬ê¸°ì„œ docstring ê¼­ ë„£ê¸°
        @tool("rag_search")
        def rag_search(query: str):
            """
            PDF ë¬¸ì„œ ë‚´ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
            """
            if not self.retriever:
                return "PDFê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ingest í•´ì£¼ì„¸ìš”."
            try:
                docs = self.retriever.get_relevant_documents(query)
                if not docs:
                    return "PDFì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                return "\n\n".join([doc.page_content for doc in docs])
            except Exception as e:
                return f"PDF ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

        tools = [google_search_tool, rag_search]

        prompt_template = PromptTemplate.from_template(
            """
            <s> [INST] ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            ì£¼ì–´ì§„ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í• ì§€ ì‹ ì¤‘í•˜ê²Œ íŒë‹¨í•˜ì„¸ìš”.
            ë§Œì•½ PDF ë¬¸ì„œì— ì •ë³´ê°€ ìˆë‹¤ë©´ 'rag_search' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³ ,
            ìµœì‹  ì •ë³´ë‚˜ ì¼ë°˜ì ì¸ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤ë©´ 'google_search' ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

            ì•„ë˜ëŠ” ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”ì…ë‹ˆë‹¤:
            {history}

            ì´ë²ˆ ì§ˆë¬¸: {input}
            {agent_scratchpad}
            [/INST]
            """
        )

        agent = create_tool_calling_agent(self.model, tools, prompt_template)
        self.chain = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)

    def get_past_user_interactions(self, user_id: str, limit: int = 3):
        if not self.vector_store:
            return []
        with self.vector_store._driver.session() as session:
            result = session.run(
                """
                MATCH (u:User {id: $uid})-[:ASKED]->(q:Question)-[:RECEIVED_ANSWER]->(a:Answer)
                RETURN q.text AS question, a.text AS answer
                ORDER BY q.timestamp DESC
                LIMIT $limit
                """,
                uid=user_id,
                limit=limit
            )
            interactions = result.data()
            return interactions[::-1]

    def _format_history(self, history: list):
        formatted_history = []
        for item in history:
            formatted_history.append(f"ì‚¬ìš©ì: {item['question']}")
            formatted_history.append(f"ì–´ì‹œìŠ¤í„´íŠ¸: {item['answer']}")
        return "\n".join(formatted_history)

    def ask(self, query: str):
        if not self.chain:
            st.warning("ê²½ê³ : ì—ì´ì „íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return "ì—ì´ì „íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

        past_history_data = []
        if self.current_user_id:
            past_history_data = self.get_past_user_interactions(self.current_user_id)
        formatted_history = self._format_history(past_history_data)

        question_id = str(uuid.uuid4())
        if self.vector_store:
            with self.vector_store._driver.session() as session:
                session.run(
                    """
                    MERGE (q:Question {id: $qid})
                    SET q.text = $qtext, q.timestamp = datetime()
                    """,
                    qid=question_id, qtext=query
                )
        else:
            st.warning("ê²½ê³ : PDFê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ì§ˆë¬¸ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        try:
            response = self.chain.invoke({"input": query, "history": formatted_history})
            answer_text = response['output']
        except Exception as e:
            st.error(f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            answer_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

        answer_id = str(uuid.uuid4())
        if self.vector_store:
            with self.vector_store._driver.session() as session:
                session.run(
                    """
                    MERGE (a:Answer {id: $aid})
                    SET a.text = $atext, a.timestamp = datetime()
                    MERGE (q:Question {id: $qid})
                    MERGE (q)-[:RECEIVED_ANSWER]->(a)
                    """,
                    aid=answer_id, atext=answer_text, qid=question_id
                )
                if self.current_user_id:
                    session.run(
                        """
                        MATCH (u:User {id: $uid}), (q:Question {id: $qid})
                        MERGE (u)-[:ASKED]->(q)
                        """,
                        uid=self.current_user_id, qid=question_id
                    )
        else:
            st.warning("ê²½ê³ : PDFê°€ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.chat_history.append((query, answer_text))
        return answer_text

    def clear(self):
        self.vector_store = None
        self.retriever = None
        self.chain = None
        self.chat_history = []
        self.current_user_id = None
        st.write("ì´ˆê¸°í™” ì™„ë£Œ!")
