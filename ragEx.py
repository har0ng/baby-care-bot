import os
from dotenv import load_dotenv # .env íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•´ ì¶”ê°€

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
# ì´ í•¨ìˆ˜ëŠ” ê°€ëŠ¥í•œ í•œ ë¹¨ë¦¬ í˜¸ì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
load_dotenv()

import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain_community.chat_models import ChatOllama
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.runnable import RunnablePassthrough
from langchain.prompts import PromptTemplate
from langchain.vectorstores.utils import filter_complex_metadata

# FastEmbedEmbeddingsëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, import ìì²´ëŠ” ë‚¨ì•„ìˆì–´ë„ ì˜¤ë¥˜ëŠ” ì•„ë‹˜.
# from langchain_community.embeddings import FastEmbedEmbeddings
# GoogleGenerativeAIEmbeddingsë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì´ ì¤„ì´ í•„ìš”í•©ë‹ˆë‹¤.
from langchain_google_genai import GoogleGenerativeAIEmbeddings

class ChatPDF:
    vector_store = None
    retriever = None
    chain = None

    def __init__(self):
        # ChatOllama ëª¨ë¸ ì„¤ì •
        self.model = ChatOllama(model="gemma3:4b")
        # í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì •
        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (í•œêµ­ì–´/ì¼ë³¸ì–´ ë‹µë³€ ì§€ì‹œ í¬í•¨)
        self.prompt = PromptTemplate.from_template(
        """
        <start_of_turn>user
        Please answer in Korean and Japanese.
        éŸ“å›½èªã¨æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
        Question: {question}
        Context: {context}
        <end_of_turn>
        <start_of_turn>model
        Here is the answer based on the provided context:

        ---
        Reference Context:
        {context}
        """
        )

    def ingest(self, pdf_file_path: str):
        st.write(f"ğŸ“„ PDF íŒŒì¼ ë¡œë“œ ì‹œì‘: {pdf_file_path}")
        docs = PyPDFLoader(file_path=pdf_file_path).load()
        st.write(f"âœ… PDF ë¡œë“œ ì™„ë£Œ, ë¬¸ì„œ ìˆ˜: {len(docs)}")

        st.write("âœ‚ï¸ í…ìŠ¤íŠ¸ ë¶„í•  ì‹œì‘")
        chunks = self.text_splitter.split_documents(docs)
        st.write(f"âœ… í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ, ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("ğŸ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì‹œì‘")
        chunks = filter_complex_metadata(chunks)
        st.write(f"âœ… ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì™„ë£Œ, í•„í„°ë§ í›„ ì²­í¬ ìˆ˜: {len(chunks)}")

        st.write("âš™ï¸ ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì‹œì‘")

        # --- GOOGLE_API_KEY ë¡œë“œ í™•ì¸ ì½”ë“œ (ì •í™•í•œ ë“¤ì—¬ì“°ê¸°) ---
        api_key_check = os.getenv("GOOGLE_API_KEY")
        if api_key_check:
            st.write(f"âœ… GOOGLE_API_KEY ë¡œë“œë¨ (ì¼ë¶€ ë¬¸ìì—´ ìˆ¨ê¹€): {api_key_check[:5]}...{api_key_check[-5:]}")
        else:
            st.write("âŒ GOOGLE_API_KEYê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        # --- í™•ì¸ ì½”ë“œ ë ---

        # Chroma ë²¡í„° ìŠ¤í† ì–´ ìƒì„± (documents=chunks ì¤‘ë³µ ì œê±°)
        vector_store = Chroma.from_documents(
            documents=chunks,
            embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001", task_type="RETRIEVAL_DOCUMENT")
        )
        st.write("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

        # ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì •
        self.retriever = vector_store.as_retriever(
            search_type="similarity_score_threshold",
            search_kwargs={
                "k": 3,
                "score_threshold": 0.5,
            },
        )
        st.write("âœ… ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ì™„ë£Œ")

        # ì²´ì¸ ì„¤ì •
        self.chain = ({"context": self.retriever, "question": RunnablePassthrough()}
                      | self.prompt
                      | self.model
                      | StrOutputParser())
        st.write("âœ… ì±— ì²´ì¸ ìƒì„± ì™„ë£Œ")

    def ask(self, query: str):
        if not self.chain:
            return "Please, add a PDF document first."
        return self.chain.invoke(query)

    def clear(self):
        self.vector_store = None
        self.retriever = None
        self.chain = None